{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730c9c0b-1484-4a22-b34d-f38be9587aba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------+----------------------+------------+----------------------+\n",
      "|COMM                 |Total_Population|Mean_Income_Per_Person|Total_Crimes|Crime_Per_Person_Ratio|\n",
      "+---------------------+----------------+----------------------+------------+----------------------+\n",
      "|Culver City          |38883           |33644.97549057429     |345         |0.00887277216264177   |\n",
      "|North Lancaster      |1151            |19097.289313640315    |0           |0.0                   |\n",
      "|Rosewood/East Gardena|1164            |16165.823024054982    |101         |0.08676975945017182   |\n",
      "|East Rancho Dominguez|15135           |8830.036339610175     |0           |0.0                   |\n",
      "|Toluca Terrace       |1301            |20167.531898539586    |289         |0.22213681783243658   |\n",
      "|Elysian Park         |5267            |13865.32770077843     |3191        |0.6058477311562559    |\n",
      "|Longwood             |4210            |13420.052256532066    |3062        |0.7273159144893112    |\n",
      "|Pico Rivera          |62942           |15157.884512726001    |2           |3.177528518318452E-5  |\n",
      "|Malibu               |12645           |67046.98133649664     |1           |7.908264136022143E-5  |\n",
      "|Green Meadows        |19821           |8027.096412895414     |21961       |1.1079662983704153    |\n",
      "|Hacienda Heights     |53594           |24046.483673545546    |0           |0.0                   |\n",
      "|Cadillac-Corning     |6665            |19572.784696174043    |3877        |0.581695423855964     |\n",
      "|West Puente Valley   |9657            |12527.325566946256    |0           |0.0                   |\n",
      "|Montebello           |62500           |14514.115728          |6           |9.6E-5                |\n",
      "|Mid-city             |14339           |21734.64899923286     |10190       |0.7106492781923426    |\n",
      "|Lake Manor           |1600            |33720.028125          |0           |0.0                   |\n",
      "|Hawaiian Gardens     |14254           |9911.840535989897     |0           |0.0                   |\n",
      "|Lincoln Heights      |31144           |10767.81132802466     |15999       |0.5137105060364757    |\n",
      "|Westlake Village     |8270            |42843.458524788395    |1           |1.2091898428053205E-4 |\n",
      "|Van Nuys             |86019           |14488.189551145677    |67745       |0.787558562643137     |\n",
      "+---------------------+----------------+----------------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total communities: 319"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from sedona.spark import SedonaContext\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Initialize Spark Session and Sedona Context\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CrimeAnalysisSpatialJoinSQL\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.sedona.sql.SedonaSqlExtensions\") \\\n",
    "    .config(\"sedona.global.charset\", \"utf8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Load datasets\n",
    "census_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "income_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\"\n",
    "crime_path = \"s3://groups-bucket-dblab-905418150721/group24/results/q2_parquet_maindata/\"\n",
    "\n",
    "# Load Census Data (GeoJSON format)\n",
    "census_df = sedona.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(census_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Flatten the GeoJSON structure and filter valid populations\n",
    "census_df = census_df.select(\n",
    "    F.col(\"properties.ZCTA10\").alias(\"ZCTA10\"),\n",
    "    F.col(\"properties.POP_2010\").alias(\"Population\"),\n",
    "    F.col(\"properties.COMM\").alias(\"COMM\"),\n",
    "    F.col(\"geometry\").alias(\"geometry\"),\n",
    "    F.col(\"properties.HOUSING10\").alias(\"HOUSING10\"),\n",
    ").filter(F.col(\"Population\") > 0)  # Exclude zero or negative population\n",
    "\n",
    "# Load Crime Data (Parquet format)\n",
    "crime_df = spark.read.parquet(crime_path)\n",
    "\n",
    "# Create geometry column using ST_Point\n",
    "crime_df = crime_df.withColumn(\"geometry\", F.expr(\"ST_Point(LON, LAT)\")) \\\n",
    "                   .select(\"geometry\")\n",
    "\n",
    "# Load Income Data (CSV format)\n",
    "income_df = spark.read.csv(income_path, header=True, inferSchema=True)\n",
    "income_df = income_df.withColumn(\n",
    "    \"Income\",\n",
    "    F.regexp_replace(F.col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"double\")\n",
    ").withColumnRenamed(\"Zip Code\",\"Zip\").drop(\"Estimated Median Income\")\n",
    "\n",
    "census_agg = census_df.groupBy(\"COMM\").agg(\n",
    "    F.sum(\"Population\").alias(\"Total_Population\"),\n",
    "    F.sum(\"HOUSING10\").alias(\"Total_Households\")\n",
    ")\n",
    "# Calculate total income per community (sum of income contributions per zip)\n",
    "income_total = census_df.join(income_df, census_df.ZCTA10 == income_df.Zip, \"inner\") \\\n",
    "    .groupBy(\"COMM\").agg(\n",
    "        F.sum(F.col(\"Income\") * F.col(\"HOUSING10\")).alias(\"Total_Income\")\n",
    "    )\n",
    "\n",
    "# Join census and income data\n",
    "census_income = census_agg.join(income_total, \"COMM\", \"inner\")\n",
    "\n",
    "# Calculate Mean Income Per Person\n",
    "census_income = census_income.withColumn(\n",
    "    \"Mean_Income_Per_Person\",\n",
    "    F.col(\"Total_Income\") / F.col(\"Total_Population\")\n",
    ")\n",
    "\n",
    "# Aggregate crime data\n",
    "crime_agg = crime_df.alias(\"cr\").join(\n",
    "    census_df.alias(\"c\"),\n",
    "    F.expr(\"ST_Within(cr.geometry, c.geometry)\"),\n",
    "    \"inner\"\n",
    ").groupBy(\"c.COMM\").agg(\n",
    "    F.count(\"*\").alias(\"Total_Crimes\")\n",
    ")\n",
    "\n",
    "# Final join for all data\n",
    "final_result = census_income.join(crime_agg, \"COMM\", \"left_outer\") \\\n",
    "    .withColumn(\n",
    "        \"Crime_Per_Person_Ratio\",\n",
    "        F.col(\"Total_Crimes\") / F.col(\"Total_Population\")\n",
    "    )\n",
    "\n",
    "# Replace NULL values with 0 in the columns \"Total_Crimes\" and \"Crime_Per_Person_Ratio\"\n",
    "final_result = final_result.fillna({\n",
    "    \"Total_Crimes\": 0,\n",
    "    \"Crime_Per_Person_Ratio\": 0\n",
    "})\n",
    "\n",
    "# Display final results\n",
    "final_result.select(\n",
    "    \"COMM\",\n",
    "    \"Total_Population\",\n",
    "    \"Mean_Income_Per_Person\",\n",
    "    \"Total_Crimes\",\n",
    "    \"Crime_Per_Person_Ratio\"\n",
    ").show(truncate=False)\n",
    "\n",
    "\n",
    "# # Broadcast Join Hint\n",
    "# broadcast_result = census_income.hint(\"broadcast\").join(crime_agg, \"COMM\", \"left_outer\")\n",
    "\n",
    "# # Explain Broadcast Plan\n",
    "# print(\"Broadcast Join Plan:\")\n",
    "# broadcast_result.explain()\n",
    "\n",
    "# # Merge Join Hint\n",
    "# merge_result = census_income.hint(\"merge\").join(crime_agg, \"COMM\", \"left_outer\")\n",
    "\n",
    "# # Explain Merge Plan\n",
    "# print(\"Merge Join Plan:\")\n",
    "# merge_result.explain()\n",
    "\n",
    "# # Shuffle Hash Join Hint\n",
    "# shuffle_hash_result = census_income.hint(\"shuffle_hash\").join(crime_agg, \"COMM\", \"left_outer\")\n",
    "\n",
    "# # Explain Shuffle Hash Plan\n",
    "# print(\"Shuffle Hash Join Plan:\")\n",
    "# shuffle_hash_result.explain()\n",
    "\n",
    "# # Shuffle Replicate NL Join Hint\n",
    "# shuffle_replicate_result = census_income.hint(\"shuffle_replicate_nl\").join(crime_agg, \"COMM\", \"left_outer\")\n",
    "\n",
    "# # Explain Shuffle Replicate NL Plan\n",
    "# print(\"Shuffle Replicate NL Join Plan:\")\n",
    "# shuffle_replicate_result.explain()\n",
    "\n",
    "# Count total rows in the final result\n",
    "print(\"Total communities:\", final_result.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816bcea7-85df-4f00-9abc-11651edf33e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Vict Descent` cannot be resolved. Did you mean one of the following? [`COMM`].\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt1/yarn/usercache/livy/appcache/application_1732639283265_1439/container_1732639283265_1439_01_000001/pyspark.zip/pyspark/sql/dataframe.py\", line 3081, in __getitem__\n",
      "    jc = self._jdf.apply(item)\n",
      "  File \"/mnt1/yarn/usercache/livy/appcache/application_1732639283265_1439/container_1732639283265_1439_01_000001/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/mnt1/yarn/usercache/livy/appcache/application_1732639283265_1439/container_1732639283265_1439_01_000001/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 185, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Vict Descent` cannot be resolved. Did you mean one of the following? [`COMM`].\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be96ea-93d4-4afb-890a-fd292a891cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
