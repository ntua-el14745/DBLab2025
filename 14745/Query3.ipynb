{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730c9c0b-1484-4a22-b34d-f38be9587aba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+----------------------+\n",
      "|COMM                   |Mean_Income_Per_Person|Crime_Per_Person_Ratio|\n",
      "+-----------------------+----------------------+----------------------+\n",
      "|Adams-Normandie        |8791.458301453711     |0.7148686559551135    |\n",
      "|Alsace                 |11239.50119372442     |0.5416098226466576    |\n",
      "|Angeles National Forest|33079.58823529412     |0.4117647058823529    |\n",
      "|Angelino Heights       |18427.059814658805    |0.5732940185341197    |\n",
      "|Arleta                 |12110.779170215355    |0.4264509064363061    |\n",
      "|Atwater Village        |28481.236967160792    |0.5288318320448259    |\n",
      "|Baldwin Hills          |17303.90612886328     |0.9950061114021302    |\n",
      "|Bel Air                |62707.32126861155     |0.39922527539038855   |\n",
      "|Beverly Crest          |22231.4086621278      |0.3689607087195472    |\n",
      "|Beverlywood            |29267.8210229561      |0.5084977849375755    |\n",
      "|Boyle Heights          |8494.108238050494     |0.6171887393378809    |\n",
      "|Brentwood              |60773.32722370128     |0.4058638814936173    |\n",
      "|Brookside              |18138.626409017714    |0.8856682769726248    |\n",
      "|Cadillac-Corning       |19572.784696174043    |0.581695423855964     |\n",
      "|Canoga Park            |19660.291873822815    |0.5506083179203503    |\n",
      "|Carthay                |49727.37476259212     |0.7628959963534149    |\n",
      "|Central                |6973.305889660624     |0.6593822350217403    |\n",
      "|Century City           |45617.76047098402     |0.632968881412952     |\n",
      "|Century Palms/Cove     |8610.314917489584     |1.1446474853187232    |\n",
      "|Chatsworth             |30694.606443388573    |0.5281029087959207    |\n",
      "|Cheviot Hills          |36416.02205474897     |0.5429458051645794    |\n",
      "|Chinatown              |14476.74654501543     |0.7242721051925399    |\n",
      "|Cloverdale/Cochran     |14663.020812544548    |0.6156094084105488    |\n",
      "|Country Club Park      |15774.632805995005    |0.7195392728281987    |\n",
      "|Crenshaw District      |14909.721909685268    |0.8927322487456287    |\n",
      "|Crestview              |33327.120074177095    |0.6660176170607325    |\n",
      "|Del Rey                |25925.892445860794    |0.48022742087347      |\n",
      "|Downtown               |19907.80560116767     |1.9612297026090129    |\n",
      "|Eagle Rock             |20730.858957523786    |0.43033632587431325   |\n",
      "|East Hollywood         |14455.3503562082      |0.7112169235242803    |\n",
      "|Echo Park              |21605.924097003444    |0.6458348596966811    |\n",
      "|El Sereno              |13556.589549051627    |0.43147845748021607   |\n",
      "|Elysian Park           |13881.140657669644    |0.5675727048089717    |\n",
      "|Elysian Valley         |16261.790473257366    |0.4363001745200698    |\n",
      "|Encino                 |38341.62713425434     |0.623780847797851     |\n",
      "|Exposition             |12334.321483771251    |0.8333848531684699    |\n",
      "|Exposition Park        |8630.630860871499     |0.8179391482735608    |\n",
      "|Faircrest Heights      |20951.107683352737    |0.7272991850989523    |\n",
      "|Figueroa Park Square   |9299.836194390715     |0.9028046421663443    |\n",
      "|Florence-Firestone     |8079.274829277236     |1.0588936248224026    |\n",
      "|Glassell Park          |18828.10489463408     |0.41496667339931326   |\n",
      "|Gramercy Place         |14936.698098639128    |1.0647620886014864    |\n",
      "|Granada Hills          |27608.016856376424    |0.5292539694047705    |\n",
      "|Green Meadows          |8029.932270112042     |1.020995255879681     |\n",
      "|Hancock Park           |21538.793404898115    |0.7797133123352832    |\n",
      "|Harbor City            |20171.128254940784    |0.4932192625247506    |\n",
      "|Harbor Gateway         |830.206846721148      |0.46035977675901935   |\n",
      "|Harbor Pines           |18800.99497487437     |0.5216994061215167    |\n",
      "|Harvard Heights        |11820.77334670521     |0.771694885257507     |\n",
      "|Harvard Park           |9844.309999451183     |1.0058449042313813    |\n",
      "|Highland Park          |16886.586701835367    |0.4456313880646225    |\n",
      "|Historic Filipinotown  |15175.546139359698    |0.8149152542372882    |\n",
      "|Hollywood              |25729.15954864739     |1.3845980743574493    |\n",
      "|Hollywood Hills        |43023.69992828971     |0.747615632843313     |\n",
      "|Hyde Park              |14144.20020758026     |1.0300275580687879    |\n",
      "|Jefferson Park         |10258.852338413031    |0.6410930110352075    |\n",
      "|Koreatown              |13590.433226982681    |0.7035095715587967    |\n",
      "|Lafayette Square       |16700.833409821018    |0.8049564020192749    |\n",
      "|Lake Balboa            |17289.1397541934      |0.5426554327381412    |\n",
      "|Lakeview Terrace       |15991.256902570613    |0.4470802919708029    |\n",
      "|Leimert Park           |16103.736870455157    |1.0560867223269594    |\n",
      "|Lincoln Heights        |10782.698819973635    |0.503488633805987     |\n",
      "|Little Armenia         |15094.265256959316    |0.8609475374732334    |\n",
      "|Little Bangladesh      |18592.773524177363    |0.728009390738006     |\n",
      "|Little Tokyo           |16505.127910685806    |2.9023923444976076    |\n",
      "|Longwood               |13420.052256532066    |0.7273159144893112    |\n",
      "|Los Feliz              |30474.495889478036    |0.7351753660553583    |\n",
      "|Manchester Square      |14589.573905662664    |1.0803928701345944    |\n",
      "|Mandeville Canyon      |55572.10949582431     |0.2610578410145376    |\n",
      "|Mar Vista              |33044.65879285221     |0.4182580463736994    |\n",
      "|Marina Peninsula       |65235.69402813004     |0.5999538851740834    |\n",
      "|Melrose                |21712.348996487024    |0.807467116908581     |\n",
      "|Mid-city               |21734.64899923286     |0.7106492781923426    |\n",
      "|Miracle Mile           |38849.36290573796     |0.6094324341162545    |\n",
      "|Mission Hills          |17152.14349105927     |0.5747111286850314    |\n",
      "|Mt. Washington         |16611.891774515763    |0.4491878745765656    |\n",
      "|North Hills            |16228.447394576175    |0.6136944483884709    |\n",
      "|North Hollywood        |17302.581613943392    |0.678377486002515     |\n",
      "|Northridge             |22839.72297308156     |0.6914262756126959    |\n",
      "|Pacific Palisades      |63835.960215157975    |0.3796762938553983    |\n",
      "|Pacoima                |11699.466401552681    |0.4793224663744079    |\n",
      "|Palisades Highlands    |66789.55961387946     |0.1878424210800939    |\n",
      "|Palms                  |28894.522975613287    |0.431748558747618     |\n",
      "|Panorama City          |10221.86143884892     |0.5084604316546762    |\n",
      "|Park La Brea           |36647.89450437442     |0.8838868597638665    |\n",
      "|Pico-Union             |10471.913615919999    |0.6938616548154476    |\n",
      "|Playa Del Rey          |45522.596580114       |0.7425585813806207    |\n",
      "|Playa Vista            |42384.83710508626     |0.5004481290611696    |\n",
      "|Porter Ranch           |35201.02371931612     |0.3803050081186921    |\n",
      "|Rancho Park            |39037.730430606694    |1.008644149191612     |\n",
      "|Regent Square          |19615.819537658463    |0.5152870991797166    |\n",
      "|Reseda                 |16927.49097719235     |0.5522153220641065    |\n",
      "|Reseda Ranch           |14318.063612099644    |0.7724644128113879    |\n",
      "|Reynier Village        |24451.135373317014    |0.619828641370869     |\n",
      "|San Pedro              |24333.32350055863     |0.68622775703736      |\n",
      "|Shadow Hills           |25204.011223344558    |0.574635241301908     |\n",
      "|Sherman Oaks           |37743.85719379349     |0.6461627363710134    |\n",
      "|Silverlake             |25007.567057165077    |0.6928349212521875    |\n",
      "|South Carthay          |39831.340037649854    |0.723174477360547     |\n",
      "|South Park             |6975.78660422875      |0.8028097062579821    |\n",
      "|St Elmo Village        |13123.889611846533    |0.6048911824096926    |\n",
      "|Studio City            |44311.4859030837      |0.7834067547723935    |\n",
      "|Sun Valley             |12304.063291386206    |0.525548726953468     |\n",
      "|Sunland                |26184.012348198798    |0.4484131033778957    |\n",
      "|Sycamore Square        |30116.823622047243    |1.1275590551181103    |\n",
      "|Sylmar                 |16322.249276111686    |0.45864788004136503   |\n",
      "|Tarzana                |29095.61605578763     |0.6433095270179221    |\n",
      "|Temple-Beaudry         |14823.108767033327    |0.6255951403710392    |\n",
      "|Thai Town              |26851.47272727273     |0.5305882352941177    |\n",
      "|Toluca Lake            |37050.74249905051     |0.7489555639954425    |\n",
      "|Toluca Terrace         |20167.531898539586    |0.22213681783243658   |\n",
      "|Toluca Woods           |24517.584109589043    |0.6301369863013698    |\n",
      "|Tujunga                |21783.987533592117    |0.43214392355927145   |\n",
      "|University Hills       |15146.115716044316    |0.3992613869511695    |\n",
      "|University Park        |6877.686675541571     |0.6973254266005083    |\n",
      "|Valley Glen            |18272.41769598301     |0.4998407361528933    |\n",
      "|Valley Village         |28196.382152861144    |0.5339913743275088    |\n",
      "|Van Nuys               |14498.302411614839    |0.7382473039472307    |\n",
      "|Venice                 |47625.344329326406    |1.0404279521628186    |\n",
      "|Vermont Knolls         |10494.04035256026     |1.0672142942798897    |\n",
      "|Vermont Square         |8329.565791341376     |0.7804116394606103    |\n",
      "|Vermont Vista          |8367.25380413058      |1.2551365756162558    |\n",
      "|Vernon Central         |6624.606504265092     |0.6563935367454068    |\n",
      "|Victoria Park          |15596.298133533759    |0.7328072153325818    |\n",
      "|View Heights           |15274.344488793367    |0.6733190052195271    |\n",
      "|Watts                  |7755.219963684051     |0.9192474528397054    |\n",
      "|Wellington Square      |13451.698088618592    |0.9695916594265855    |\n",
      "|West Adams             |10768.299623210249    |0.7500753579502637    |\n",
      "|West Hills             |28761.284715519265    |0.45535178566770146   |\n",
      "|West Los Angeles       |39729.36480234261     |0.61900439238653      |\n",
      "|West Vernon            |8722.73435387674      |1.0376739562624255    |\n",
      "|Westchester            |34358.788543049195    |0.5650126300466669    |\n",
      "|Westlake               |10119.666093069234    |0.7994727785303701    |\n",
      "|Westwood               |27245.334176375472    |0.3466147021020772    |\n",
      "|Wholesale District     |9847.942996295787     |1.5441418575936343    |\n",
      "|Wilmington             |11157.1196            |0.6250666666666667    |\n",
      "|Wilshire Center        |15981.738162267426    |0.797324471350253     |\n",
      "|Winnetka               |19638.692998054434    |0.5406790652915211    |\n",
      "|Woodland Hills         |37616.292674067874    |0.5450941995799314    |\n",
      "+-----------------------+----------------------+----------------------+\n",
      "\n",
      "Total communities: 139"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from sedona.spark import SedonaContext\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Initialize Spark Session and Sedona Context\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CrimeAnalysisSpatialJoinSQL\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.sedona.sql.SedonaSqlExtensions\") \\\n",
    "    .config(\"sedona.global.charset\", \"utf8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Load datasets\n",
    "census_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "income_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\"\n",
    "crime_path = \"s3://groups-bucket-dblab-905418150721/group24/results/q2_parquet_maindata/\"\n",
    "\n",
    "# Load Census Data (GeoJSON format)\n",
    "census_df = sedona.read.format(\"geojson\") \\\n",
    "    .option(\"multiLine\", \"true\").load(census_path) \\\n",
    "    .selectExpr(\"explode(features) as features\") \\\n",
    "    .select(\"features.*\")\n",
    "\n",
    "# Flatten the GeoJSON structure and filter valid populations\n",
    "census_df = census_df.select(\n",
    "    F.col(\"properties.ZCTA10\").alias(\"ZCTA10\"),\n",
    "    F.col(\"properties.POP_2010\").alias(\"Population\"),\n",
    "    F.col(\"properties.COMM\").alias(\"COMM\"),\n",
    "    F.col(\"geometry\").alias(\"geometry\"),\n",
    "    F.col(\"properties.HOUSING10\").alias(\"HOUSING10\"),\n",
    "    F.col(\"properties.CITY\").alias(\"CITY\"),\n",
    ").filter((F.col(\"CITY\") == \"Los Angeles\")& (F.col(\"Population\") > 0) & (F.col(\"HOUSING10\") > 0))\n",
    "\n",
    "# # Update rows where Population = 0 and HOUSING10 > 0 to set HOUSING10 = 0\n",
    "# census_df = census_df.withColumn(\n",
    "#     \"HOUSING10\",\n",
    "#     F.when((F.col(\"Population\") == 0) & (F.col(\"HOUSING10\") > 0), 0).otherwise(F.col(\"HOUSING10\"))\n",
    "# ).filter(F.col(\"Population\") > 0)  # Filter rows where Population is greater than 0\n",
    "\n",
    "# Load Crime Data (Parquet format)\n",
    "crime_df = spark.read.parquet(crime_path)\n",
    "\n",
    "# Create geometry column using ST_Point\n",
    "crime_df = crime_df.withColumn(\"geometry\", F.expr(\"ST_Point(LON, LAT)\")) \\\n",
    "                   .select(\"geometry\")\n",
    "\n",
    "# Load Income Data (CSV format)\n",
    "income_df = spark.read.csv(income_path, header=True, inferSchema=True)\n",
    "income_df = income_df.withColumn(\n",
    "    \"Income\",\n",
    "    F.regexp_replace(F.col(\"Estimated Median Income\"), \"[$,]\", \"\").cast(\"double\")\n",
    ").withColumnRenamed(\"Zip Code\", \"Zip\").drop(\"Estimated Median Income\") \\\n",
    " .filter(F.col(\"Community\").contains(\"Los Angeles\"))\n",
    "\n",
    "census_agg = census_df.groupBy(\"COMM\").agg(\n",
    "    F.sum(\"Population\").alias(\"Total_Population\"),\n",
    "    F.sum(\"HOUSING10\").alias(\"Total_Households\")\n",
    ")\n",
    "# Calculate total income per community (sum of income contributions per zip)\n",
    "income_total = census_df.join(income_df, census_df.ZCTA10 == income_df.Zip, \"inner\") \\\n",
    "    .groupBy(\"COMM\").agg(\n",
    "        F.sum(F.col(\"Income\") * F.col(\"HOUSING10\")).alias(\"Total_Income\")\n",
    "    )\n",
    "\n",
    "# Join census and income data\n",
    "census_income = census_agg.join(income_total, \"COMM\", \"inner\")\n",
    "\n",
    "# Calculate Mean Income Per Person\n",
    "census_income = census_income.withColumn(\n",
    "    \"Mean_Income_Per_Person\",\n",
    "    F.col(\"Total_Income\") / F.col(\"Total_Population\")\n",
    ")\n",
    "\n",
    "# Aggregate crime data\n",
    "crime_agg = crime_df.alias(\"cr\").join(\n",
    "    census_df.alias(\"c\"),\n",
    "    F.expr(\"ST_Within(cr.geometry, c.geometry)\"),\n",
    "    \"inner\"\n",
    ").groupBy(\"c.COMM\").agg(\n",
    "    F.count(\"*\").alias(\"Total_Crimes\")\n",
    ")\n",
    "\n",
    "# Final join for all data\n",
    "final_result = census_income.join(crime_agg, \"COMM\") \\\n",
    "    .withColumn( #, \"left_outer\") \\\n",
    "        \"Crime_Per_Person_Ratio\",\n",
    "        F.col(\"Total_Crimes\") / F.col(\"Total_Population\")\n",
    "    )\n",
    "\n",
    "# Replace NULL values with 0 in the columns \"Total_Crimes\" and \"Crime_Per_Person_Ratio\"\n",
    "final_result = final_result.fillna({\n",
    "    \"Total_Crimes\": 0,\n",
    "    \"Crime_Per_Person_Ratio\": 0\n",
    "})\n",
    "\n",
    "# Display final results\n",
    "final_result.select(\n",
    "    \"COMM\",\n",
    "    # \"Total_Population\",\n",
    "    \"Mean_Income_Per_Person\",\n",
    "    # \"Total_Crimes\",\n",
    "    \"Crime_Per_Person_Ratio\",\n",
    "    # \"Total_Households\"\n",
    ").sort(\"COMM\").show(140, truncate=False)\n",
    "\n",
    "\n",
    "# # Broadcast Join Hint\n",
    "# broadcast_result = census_income.hint(\"broadcast\").join(crime_agg, \"COMM\", \"left_outer\")\n",
    "\n",
    "# # Explain Broadcast Plan\n",
    "# print(\"Broadcast Join Plan:\")\n",
    "# broadcast_result.explain()\n",
    "\n",
    "# # Merge Join Hint\n",
    "# merge_result = census_income.hint(\"merge\").join(crime_agg, \"COMM\", \"left_outer\")\n",
    "\n",
    "# # Explain Merge Plan\n",
    "# print(\"Merge Join Plan:\")\n",
    "# merge_result.explain()\n",
    "\n",
    "# # Shuffle Hash Join Hint\n",
    "# shuffle_hash_result = census_income.hint(\"shuffle_hash\").join(crime_agg, \"COMM\", \"left_outer\")\n",
    "\n",
    "# # Explain Shuffle Hash Plan\n",
    "# print(\"Shuffle Hash Join Plan:\")\n",
    "# shuffle_hash_result.explain()\n",
    "\n",
    "# # Shuffle Replicate NL Join Hint\n",
    "# shuffle_replicate_result = census_income.hint(\"shuffle_replicate_nl\").join(crime_agg, \"COMM\", \"left_outer\")\n",
    "\n",
    "# # Explain Shuffle Replicate NL Plan\n",
    "# print(\"Shuffle Replicate NL Join Plan:\")\n",
    "# shuffle_replicate_result.explain()\n",
    "\n",
    "# Count total rows in the final result\n",
    "print(\"Total communities:\", final_result.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be96ea-93d4-4afb-890a-fd292a891cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load Census Data (GeoJSON format)\n",
    "\n",
    "\n",
    "# census_df1 = sedona.read.format(\"geojson\") \\\n",
    "#     .option(\"multiLine\", \"true\").load(census_path) \\\n",
    "#     .selectExpr(\"explode(features) as features\") \\\n",
    "#     .select(\"features.*\")\n",
    "# census_df1 = census_df1.select(\n",
    "#     F.col(\"properties.ZCTA10\").alias(\"ZCTA10\"),\n",
    "#     F.col(\"properties.POP_2010\").alias(\"Population\"),\n",
    "#     F.col(\"properties.COMM\").alias(\"COMM\"),\n",
    "#     # F.col(\"geometry\").alias(\"geometry\"),\n",
    "#     F.col(\"properties.HOUSING10\").alias(\"HOUSING10\"),\n",
    "#     F.col(\"properties.CITY\").alias(\"CITY\"),\n",
    "#     F.col(\"properties.CITYCOM\").alias(\"CITYCOM\"),\n",
    "# ).filter(F.col(\"Population\") == 0)  # Exclude zero or negative population\n",
    "    \n",
    "# # ).filter(F.col(\"Population\") >= 0).filter(F.col(\"CITY\") == \"Unincorporated\")  # Exclude zero or negative population\n",
    "# # ).filter(F.col(\"COMM\") == \"Angeles National Forest\")  # Exclude zero or negative population\n",
    "# # ).filter((((F.col(\"HOUSING10\") == 0) & (F.col(\"Population\") != 0)) | \\\n",
    "# #          ((F.col(\"HOUSING10\") != 0) & (F.col(\"Population\") == 0))) & \\\n",
    "# #          (F.col(\"CITY\") == \"Los Angeles\"))  # Exclude zero or negative population\n",
    "\n",
    "\n",
    "\n",
    "# census_df1.show(200, truncate = False)\n",
    "# census_df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea01428-c806-488b-9048-9d31bcf1e9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To evaluate the performance of the joins and decide the best-suited one, here’s a consolidated analysis of the **Shuffle Hash Join**, **Broadcast Hash Join**, and **Shuffle Replicate Nested Loop Join** from the physical plans you provided:\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **1. Shuffle Hash Join**:\n",
    "# - **Description**: \n",
    "#   - The **Shuffle Hash Join** partitions the data on both sides of the join condition (`COMM`) and distributes it across the cluster. Each partition processes the join locally.\n",
    "#   - It is typically used when both datasets are large but can still fit into memory after partitioning.\n",
    "\n",
    "# - **Advantages**:\n",
    "#   - Scales well for large datasets.\n",
    "#   - Ensures distributed parallelism for performance.\n",
    "\n",
    "# - **Disadvantages**:\n",
    "#   - Shuffle operations are expensive in terms of network I/O.\n",
    "#   - Performance can degrade significantly if the data skew exists (i.e., when certain `COMM` values have significantly more rows than others).\n",
    "\n",
    "# - **Best Suited**: \n",
    "#   - When both datasets are large and can be efficiently partitioned on the join key.\n",
    "#   - Works well for **equi-joins**.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **2. Broadcast Hash Join**:\n",
    "# - **Description**: \n",
    "#   - The **Broadcast Hash Join** replicates the smaller dataset across all worker nodes. The larger dataset is then scanned, and join conditions are evaluated using the replicated smaller dataset.\n",
    "\n",
    "# - **Advantages**:\n",
    "#   - Extremely fast for joins where one dataset is small enough to fit in memory.\n",
    "#   - Avoids the shuffle cost for the smaller dataset.\n",
    "\n",
    "# - **Disadvantages**:\n",
    "#   - Memory-intensive, as the smaller dataset must be broadcast to all nodes.\n",
    "#   - Not suitable if the smaller dataset cannot fit into memory.\n",
    "\n",
    "# - **Best Suited**: \n",
    "#   - When one dataset is much smaller than the other (e.g., a lookup table or filtered spatial data).\n",
    "#   - Effective for **equi-joins** when broadcast conditions are met.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **3. Shuffle Replicate Nested Loop Join (NL Join)**:\n",
    "# - **Description**: \n",
    "#   - The **Shuffle Replicate NL Join** replicates one dataset across all partitions of the other and evaluates the join condition for all record pairs. It is typically used for **non-equi joins** or spatial joins involving complex predicates (e.g., `WITHIN`).\n",
    "\n",
    "# - **Advantages**:\n",
    "#   - Handles complex, non-equi join conditions like spatial predicates efficiently.\n",
    "#   - Can process joins when no other join types are applicable.\n",
    "\n",
    "# - **Disadvantages**:\n",
    "#   - Extremely expensive due to the Cartesian product nature of nested loops.\n",
    "#   - Requires significant memory and processing power, especially for large datasets.\n",
    "\n",
    "# - **Best Suited**:\n",
    "#   - When the join condition involves non-equi predicates (e.g., spatial predicates like `WITHIN` or `OVERLAPS`).\n",
    "#   - For datasets where one side can be replicated without memory issues.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **Consolidated Comparison**:\n",
    "# | Join Type                   | Best for                   | Limitations                            | Cost Efficiency |\n",
    "# |-----------------------------|----------------------------|----------------------------------------|-----------------|\n",
    "# | **Shuffle Hash Join**       | Large datasets, equi-joins | Expensive shuffle, sensitive to skew  | Moderate        |\n",
    "# | **Broadcast Hash Join**     | One small, one large set   | Memory constraints, large broadcasts   | High (if feasible) |\n",
    "# | **Shuffle Replicate NL Join** | Non-equi or spatial joins | Extremely costly for large datasets    | Low (except spatial) |\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **Which is the Best?**\n",
    "# 1. **For Equi-Joins**:\n",
    "#    - If both datasets are large: **Shuffle Hash Join**.\n",
    "#    - If one dataset is small: **Broadcast Hash Join**.\n",
    "\n",
    "# 2. **For Spatial Joins** (non-equi predicates like `WITHIN`):\n",
    "#    - **Shuffle Replicate NL Join** is necessary but should be optimized by:\n",
    "#      - Ensuring the replicated dataset is as small as possible.\n",
    "#      - Using spatial indexes or specialized libraries (e.g., Sedona) to reduce computation costs.\n",
    "\n",
    "# ---\n",
    "\n",
    "# Given the dataset sizes\n",
    "\n",
    "# 1. **Income Dataset**: ~13KB (very small).\n",
    "# 2. **Census Dataset**: ~184MB (moderately large).\n",
    "# 3. **Crime Dataset**: ~500MB (large, split into two parts).\n",
    "\n",
    "# Here’s how this impacts the choice of join strategies for the different datasets:\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **Analysis of Joins**\n",
    "\n",
    "# #### **1. Broadcast Hash Join**:\n",
    "# - **Best Scenario**:\n",
    "#   - **Broadcast the Income Dataset** (~13KB) as it is very small and fits easily in memory.\n",
    "#   - This avoids shuffling the larger Census or Crime datasets.\n",
    "# - **Usage**:\n",
    "#   - Use Broadcast Hash Join for the join between the **Income** dataset and the **Census** dataset.\n",
    "#   - Suitable for the equi-join on `COMM` or similar simple keys.\n",
    "\n",
    "# #### **2. Shuffle Hash Join**:\n",
    "# - **Best Scenario**:\n",
    "#   - When joining **Census** (~184MB) with **Crime** (~500MB).\n",
    "#   - These datasets are too large to broadcast, so shuffling and partitioning on the join key (`COMM`) ensures distributed computation.\n",
    "# - **Usage**:\n",
    "#   - Apply for joins between the larger datasets (Census and Crime) where an equi-join is possible.\n",
    "\n",
    "# #### **3. Shuffle Replicate NL Join**:\n",
    "# - **Best Scenario**:\n",
    "#   - Necessary for spatial joins like the **WITHIN** operation between **Census** and **Crime** datasets.\n",
    "#   - Since spatial joins typically involve non-equi conditions, NL Join is required.\n",
    "# - **Optimizations**:\n",
    "#   - Reduce the dataset size before the join:\n",
    "#     - Use spatial filtering or pre-aggregation to limit the number of rows in the Census or Crime datasets.\n",
    "#     - Partition the Crime data intelligently to minimize replication overhead.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **Suggested Join Strategy**\n",
    "\n",
    "# 1. **Income Join (Income + Census)**:\n",
    "#    - Use a **Broadcast Hash Join**.\n",
    "#    - Broadcast the Income dataset (13KB) and join with the Census dataset (184MB).\n",
    "#    - This ensures minimal shuffle and high performance.\n",
    "\n",
    "# 2. **Census and Crime Data Join**:\n",
    "#    - If it's a **spatial join** (e.g., `WITHIN`), use **Shuffle Replicate NL Join**:\n",
    "#      - Optimize by pre-aggregating or filtering both datasets to reduce their sizes.\n",
    "#      - Use libraries like **Sedona** for spatial indexing and faster computation.\n",
    "#    - If it's an **equi-join** on `COMM` or similar, use **Shuffle Hash Join**:\n",
    "#      - Partition both datasets on the join key to avoid excessive shuffling.\n",
    "\n",
    "# 3. **Final Join (All Data Combined)**:\n",
    "#    - Perform the joins in stages, starting with smaller datasets (Income + Census), then join the resulting dataset with the larger Crime dataset.\n",
    "#    - This hierarchical join approach minimizes intermediate data size and computational overhead.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### **Conclusion**\n",
    "\n",
    "# - **Primary Strategy**: Use **Broadcast Hash Join** wherever possible (Income + Census), as the Income dataset is very small.\n",
    "# - **Fallback Strategy**: Use **Shuffle Hash Join** for larger datasets (Census + Crime).\n",
    "# - **Spatial Joins**: For spatial operations (`WITHIN`), optimize the **Shuffle Replicate NL Join** by reducing data size or using spatial indexes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
