{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8bfd658-378c-4a40-8186-296a935c14db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 7.61 seconds\n",
      "+------------+------+\n",
      "|   Age_Group| count|\n",
      "+------------+------+\n",
      "|      Adults|121052|\n",
      "|Young Adults| 33588|\n",
      "|    Children| 15923|\n",
      "|     Seniors|  5985|\n",
      "+------------+------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import trim, lower, col, when, desc\n",
    "import time\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Query1_DataFrame\") \\\n",
    "    .config(\"spark.executor.instances\", 4) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "# Load crime data\n",
    "# Load the 2010-2019 crime data\n",
    "crime_df_2010_2019 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", \n",
    "    header=True\n",
    ")\n",
    "\n",
    "# Load the 2020-present crime data\n",
    "crime_df_2020_present = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\", \n",
    "    header=True\n",
    ")\n",
    "crime_df = crime_df_2010_2019.union(crime_df_2020_present)\n",
    "\n",
    "\n",
    "# crime_df.select(\"Crm Cd Desc\", \"LAT\", \"LON\").show(10, truncate=False)\n",
    "\n",
    "# Clean up 'Crm Cd Desc' column and apply filters\n",
    "filtered_df = crime_df.filter(\n",
    "    (lower(trim(col(\"Crm Cd Desc\"))).contains(\"aggravated assault\")) &  # Case-insensitive match\n",
    "    (col(\"LAT\").isNotNull() & col(\"LON\").isNotNull() & (col(\"LAT\") != 0) & (col(\"LON\") != 0))  # Valid coordinates\n",
    ")\n",
    "\n",
    "# filtered_df.select(\"Crm Cd Desc\", \"LAT\", \"LON\").show(10, truncate=False)\n",
    "# filtered_df.count()\n",
    "\n",
    "# Add Age Group column based on 'Vict Age'\n",
    "age_grouped_df = filtered_df.withColumn(\n",
    "    \"Age_Group\",\n",
    "    when(col(\"Vict Age\").cast(\"int\") < 18, \"Children\")\n",
    "    .when((col(\"Vict Age\").cast(\"int\") >= 18) & (col(\"Vict Age\").cast(\"int\") <= 24), \"Young Adults\")\n",
    "    .when((col(\"Vict Age\").cast(\"int\") >= 25) & (col(\"Vict Age\").cast(\"int\") <= 64), \"Adults\")\n",
    "    .when(col(\"Vict Age\").cast(\"int\") > 64, \"Seniors\")\n",
    ")\n",
    "\n",
    "# Group by Age Group and count incidents, then sort\n",
    "result_df = age_grouped_df.groupBy(\"Age_Group\").count().orderBy(desc(\"count\"))\n",
    "\n",
    "# Stop timing and print out the execution duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Write results\n",
    "group_number = \"24\"\n",
    "\n",
    "s3_path = \"s3://groups-bucket-dblab-905418150721/group\"+group_number+\"/results/\"\n",
    "\n",
    "result_df.write.mode(\"overwrite\").parquet(s3_path + \"q1_dataframe_output\")\n",
    "\n",
    "# Show results\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a403232-5242-43b8-b830-c091c01b5fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346cdc2-6279-4a37-a8b9-e917d4cb2326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
